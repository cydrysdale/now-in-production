<!doctype html>
<html lang="en">
<head>
  <script>
    try {
      const t = localStorage.getItem('theme');
      if (t === 'dark' || t === 'light') document.documentElement.setAttribute('data-theme', t);
    } catch {}
  </script>
  <meta charset="utf-8" />
  <title>How ChatGPT Works</title>
  <link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png">
  <link rel="icon" href="images/favicon.ico" type="image/x-icon">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="description" content="An approachable guide explaining how large language models work." />
  <meta name="keywords" content="RGB to CMYK, hex to CMYK, sRGB to CMYK, ICC profiles, US Web Coated SWOP v2, FOGRA39, GRACoL, LittleCMS, rendering intents, relative colorimetric, perceptual, CIELAB, XYZ, soft proofing, GCR, UCR, total ink limit, Pantone to CMYK, print production, color management">
  <meta name="guide:category" content="AI" />
  <meta name="guide:updated" content="2025-09-05" />
  <link rel="canonical" href="https://cydrysdale.github.io/now-in-production/how-llms-work.html">
  <meta name="robots" content="index,follow">
  <meta name="author" content="Chris Yasuda Drydsale">
  <meta name="format-detection" content="telephone=no"/>
  <!-- Open Graph for Facebook, LinkedIn, etc. -->
  <meta property="og:type" content="article">
  <meta property="og:title" content="How ChatGPT Works">
  <meta property="og:description" content="An approachable guide explaining how large language models work.">
  <meta property="og:image" content="https://cydrysdale.github.io/now-in-production/images/rgb-to-cmyk-guide.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />
  <meta property="og:url" content="https://cydrysdale.github.io/now-in-production/how-llms-work.html">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=VT323&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Fredericka+the+Great&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="style.css">
  <script src="core.js" defer></script>
  <script src="sandbox.js" defer></script>
  <style>
        /* Purposeful demo reveal */
    .demo-reveal{opacity:.15; transform:translateY(10px); transition:opacity .6s ease, transform .6s ease}
    .demo-reveal.is-visible{opacity:1; transform:none}

    /* Inline callouts */
    .callout{border:1px solid #2a3040; border-radius:14px; padding:12px 14px; background:#121620; color:var(--muted)}
    .badge{display:inline-block; padding:.15rem .5rem; border:1px solid #2a3040; border-radius:999px; font-size:.85rem; color:var(--muted)}

    /* Back to top */
    .toTop{position:fixed; right:16px; bottom:16px; padding:.6rem .8rem; border-radius:12px; background:#121620; border:1px solid #2a3040; box-shadow:var(--shadow); display:none}
    .toTop.show{display:inline-flex}

    /* Simple code style */
    pre{background:#0b0d12; border:1px solid #2a3040; border-radius:14px; padding:12px; overflow:auto}
    code{font-family:ui-monospace, SFMono-Regular, Menlo, Consolas, monospace}
    .muted{color:var(--muted)}
  </style>
</head>
<body>
  <a class="skip-link" href="#content">Skip to content</a>
  <header>
    <div class="header-inner">
      <img src="images/apple-touch-icon.png" width="60px" style="display: inline-block; margin-right: 10px;" alt="site logo"/>
      <div id="top" class="title-block">
        <h1>End of HumAnIty: How LLMs Work</h1>
        <div class="sub">A walkthrough of large language models.</div>
      </div>
      <div class="header-actions">
        <div class="theme-toggle" style="scale: 75%;">
          <input id="themeSwitch" type="checkbox" role="switch" aria-checked="false" aria-label="Toggle dark mode">
          <label for="themeSwitch">
            <span class="track" aria-hidden="true"></span>
            <span class="thumb" aria-hidden="true">
              <span class="icon sun">&#9788;</span>
              <span class="icon moon">&#9789;</span>
            </span>
          </label>
        </div>
        <div class="toc-mobile">
          <button id="tocToggle" aria-expanded="false" aria-controls="tocList">☰ Contents</button>
          <nav id="tocList" class="toc" aria-label="On this page"></nav>
        </div>
      </div>
  </header>

  <div class="page">
    <aside class="toc-desktop">
      <nav class="toc" aria-label="On this page"></nav>
    </aside>
    <main>

      <section id="intro" class="card">
        <h2>The Food Truck Analogy</h2>
        <p>Imagine ChatGPT as a virtual food truck. You (the customer) ask for something; the kitchen (the model) uses its pantry of language to prepare a response; then it serves you an answer. The goal: fast, tasty, and helpful.</p>
        <p class="callout">Analogy scope: The truck is a metaphor for <strong>how</strong> ideas flow, not <em>where</em> the model is hosted or <em>what</em> data it stores.</p>
      </section>

      <section id="ingredients" class="card">
        <h2>Ingredients: What an LLM Learns</h2>
        <p>An LLM is trained on lots of text. It doesn’t memorize full documents like a filing cabinet; it learns <em>patterns</em> — associations between tokens (word pieces) and contexts. That lets it generalize to new prompts.</p>
        <ul>
          <li><strong>Tokens</strong>: pieces of words the model understands.</li>
          <li><strong>Parameters</strong>: numerical weights learned during training.</li>
          <li><strong>Context window</strong>: how much of the conversation the model can “see” at once.</li>
        </ul>
      </section>

      <section id="orders" class="card">
        <h2>Taking Orders: Natural Language Processing (NLP)</h2>
        <p>NLP is how the system interprets your request. It standardizes text (tokenization), tracks conversation state, and routes your prompt to the model with system rules and tools when relevant.</p>
        <div class="callout">
          <strong>Myth</strong>: “It just picks a few keywords.”<br/>
          <span class="muted">Reality: It encodes the whole prompt and recent context into vectors the model uses to reason about likely continuations.</span>
        </div>
      </section>

      <section id="cooking" class="card">
        <h2>Cooking: Token-by-Token Prediction <span class="badge">Demo</span></h2>
        <p>This is the <em>only</em> scroll-triggered reveal in the page, used to illustrate how outputs are assembled one token at a time.</p>
        <div class="demo-reveal" id="tokenDemo">
          <p class="muted">Prompt</p>
          <pre><code id="demoPrompt">Explain photosynthesis in one sentence.</code></pre>
          <p class="muted">Model output (revealed like words hitting the plate):</p>
          <pre><code id="demoOut">▁</code></pre>
        </div>
        <p class="callout">Under the hood: the model samples the next token from a probability distribution (adjusted by settings like temperature and top‑p), then repeats.</p>
      </section>

      <section id="serving" class="card">
        <h2>Serving: The Response</h2>
        <p>Once generated, the text is streamed back to you. Apps may add formatting, citations, or follow‑ups. If tools are enabled, the system can call calculators, web search, or code sandboxes and summarize the results back to you.</p>
      </section>

      <section id="custom" class="card">
        <h2>Variety & Customization</h2>
        <ul>
          <li><strong>Style control</strong>: prompts and system instructions shape the tone.</li>
          <li><strong>Memory & settings</strong>: can steer responses over time (within privacy controls).</li>
          <li><strong>Tool use</strong>: models can fetch data or perform actions when permitted.</li>
        </ul>
      </section>

      <section id="quality" class="card">
        <h2>Quality & Accuracy</h2>
        <p>LLMs can be impressively helpful and also confidently wrong. Guardrails include retrieval (grounding answers in sources), tool calls, and user review. Treat outputs as a starting point when stakes are high.</p>
        <ul>
          <li><strong>Strengths</strong>: speed, breadth, drafting, explanation, transformation.</li>
          <li><strong>Limits</strong>: outdated knowledge, plausibility over truth, ambiguous prompts.</li>
        </ul>
      </section>

      <section id="faq" class="card">
        <h2>Quick FAQs</h2>
        <details>
          <summary>Does it learn from my inputs?</summary>
          <p>Depends on product settings. Enterprise setups typically opt out by default or require explicit consent and controls.</p>
        </details>
        <details>
          <summary>Is it searching the web?</summary>
          <p>Only if the app connects it to a browser/tool. Base generation is pattern completion, not live search.</p>
        </details>
        <details>
          <summary>Why does it sometimes make things up?</summary>
          <p>Because it’s predicting likely text, not verifying facts. Retrieval, citations, and tools reduce this risk.</p>
        </details>
      </section>

      <footer class="sub glass">
        <span>© 2025 – RGB→CMYK guide by Chris Yasuda Drysdale</span>
      </footer>
      
    </main>
  </div>
  <button id="tocFab" class="toc-fab" aria-controls="tocList" aria-expanded="false" aria-label="Open table of contents">☰ Inventory</button>
  <a id="toTop" href="#top" title="Back to top">&#8593;</a>

  <script>
    // Back to top visibility
    const toTop = document.getElementById('toTop');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 600) toTop.classList.add('show');
      else toTop.classList.remove('show');
    });

    // Simple TOC highlight
    const sections = [...document.querySelectorAll('main section')];
    const tocLinks = [...document.querySelectorAll('.toc a')];
    const byId = id => document.querySelector(`.toc a[href="#${id}"]`);
    const obsTOC = new IntersectionObserver(entries => {
      entries.forEach(e => {
        if (e.isIntersecting) {
          tocLinks.forEach(a => a.classList.remove('active'));
          const a = byId(e.target.id); if (a) a.classList.add('active');
        }
      });
    }, { rootMargin: '-40% 0px -55% 0px', threshold: 0.01 });
    sections.forEach(s => obsTOC.observe(s));

    // Purposeful, single demo reveal + token simulation
    const demo = document.getElementById('tokenDemo');
    const out = document.getElementById('demoOut');
    const sentence = "Photosynthesis is how plants use light energy to convert water and carbon dioxide into sugars, releasing oxygen.";
    let played = false;
    const obsDemo = new IntersectionObserver(entries => {
      entries.forEach(e => {
        if (e.isIntersecting && !played) {
          played = true;
          demo.classList.add('is-visible');
          // token-like reveal (word chunks)
          const tokens = sentence.split(/(\s+)/);
          let i = 0; out.textContent = '';
          const tick = () => {
            if (i < tokens.length) { out.textContent += tokens[i++]; setTimeout(tick, 65); }
          }; tick();
        }
      });
    }, { threshold: 0.35 });
    obsDemo.observe(demo);
  </script>
</body>
</html>
